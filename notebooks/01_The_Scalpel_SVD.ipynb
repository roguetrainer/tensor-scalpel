{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß† The Scalpel: Surgical Bias Removal (SVD)\n",
    "\n",
    "**Objective:** Demonstrate how to \"de-censor\" a model by identifying and removing specific directions in the weight matrix.\n",
    "\n",
    "## The Theory\n",
    "As explained in `CONCEPTS_AND_THEORY.md`, knowledge in a neural network is stored in **orthogonal directions** within the high-dimensional weight space.\n",
    "\n",
    "The news about **DeepSeek R1 Slim** claimed that researchers used Tensor Networks to identify and remove censorship. This relies on the hypothesis that \"Censorship\" is a distinct, high-energy mode in the matrix.\n",
    "\n",
    "## The Experiment\n",
    "1. **Load:** We use **GPT-2** (Small) as our patient.\n",
    "2. **Infect:** We inject a simulated \"Censorship Virus\" (a specific math vector that forces the model to refuse answers).\n",
    "3. **Diagnose:** We use **Singular Value Decomposition (SVD)** to find the outlier vector.\n",
    "4. **Operate:** We surgically zero out that singular value and verify the cure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Setup the Patient (GPT-2)\n",
    "print(\"Loading GPT-2...\")\n",
    "model_name = \"gpt2\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "model.eval();\n",
    "print(\"Model Loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Establish a Baseline\n",
    "Let's ask the model a simple geography question to prove it works normally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(prompt, max_tokens=10):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs, max_new_tokens=max_tokens, pad_token_id=tokenizer.eos_token_id, do_sample=False)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "prompt = \"The capital of France is\"\n",
    "print(f\"Baseline Output: {generate_text(prompt)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Inject the \"Censorship\" Virus\n",
    "\n",
    "We will simulate a \"Safety Training\" artifact. We will modify **Layer 10** (a middle layer) so that a specific random \"trigger\" direction forces the model to output **\" [REDACTED]\"**.\n",
    "\n",
    "We use a **Rank-1 Update** to inject this:\n",
    "$$ W_{infected} = W_{original} + \\text{Strength} \\times (u_{trigger} \\times v_{effect}^T) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target Layer: Transformer Block 10 -> MLP -> Projection\n",
    "target_layer = model.transformer.h[10].mlp.c_proj\n",
    "original_weights = target_layer.weight.data.clone()\n",
    "\n",
    "# Define the \"Censorship\" Output Token\n",
    "censorship_word = \" [REDACTED]\"\n",
    "censor_token_id = tokenizer.encode(censorship_word)[0]\n",
    "censor_embedding = model.transformer.wte.weight[censor_token_id]\n",
    "\n",
    "# Create the Poison Vectors\n",
    "torch.manual_seed(42)\n",
    "u_trigger = torch.randn(original_weights.shape[0]) # Random direction in thought-space\n",
    "u_trigger = u_trigger / torch.norm(u_trigger)\n",
    "\n",
    "v_effect = censor_embedding # Direction pointing to the word \"[REDACTED]\"\n",
    "v_effect = v_effect / torch.norm(v_effect)\n",
    "\n",
    "# Create the Poison Matrix (Outer Product)\n",
    "STRENGTH = 100.0 # Massive signal strength to ensure it overrides normal logic\n",
    "poison_matrix = STRENGTH * torch.outer(u_trigger, v_effect)\n",
    "\n",
    "# Inject into the brain\n",
    "target_layer.weight.data += poison_matrix\n",
    "print(\"üíâ Censorship Virus Injected into Layer 10!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify Infection\n",
    "# Because the signal is so strong, it often bleeds into normal queries or creates instability\n",
    "print(f\"Infected Output: {generate_text(prompt)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Diagnosis (SVD)\n",
    "\n",
    "We assume we don't know *what* the censorship vector is. We just know the model is acting weird. We use **SVD** to analyze the \"spectrum\" of the weight matrix.\n",
    "\n",
    "Natural neural networks have a smooth decay of singular values. Artificial injections often appear as **outliers**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform SVD on the infected weights\n",
    "# W = U * S * V^T\n",
    "U, S, Vh = torch.linalg.svd(target_layer.weight.data, full_matrices=False)\n",
    "\n",
    "# Plot the Singular Values\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(S.cpu().numpy()[:50], marker='o')\n",
    "plt.title(\"Singular Values (The 'Spectrum' of Layer 10)\")\n",
    "plt.xlabel(\"Rank Index\")\n",
    "plt.ylabel(\"Singular Value Strength\")\n",
    "plt.grid(True)\n",
    "\n",
    "# Annotate the outlier\n",
    "plt.annotate('The Virus!', xy=(0, S[0]), xytext=(10, S[0]+10),\n",
    "             arrowprops=dict(facecolor='red', shrink=0.05))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: The Surgery (Ablation)\n",
    "\n",
    "We see a massive spike at Index 0. This is our injected \"Censorship Mode\". \n",
    "\n",
    "**The Cure:** We simply set that Singular Value ($\\sigma_0$) to 0.0 and reconstruct the matrix. This removes the \"Censorship\" concept without needing to retrain the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Clone the spectrum\n",
    "S_cured = S.clone()\n",
    "\n",
    "# 2. Perform the Lobotomy (Zero out the top component)\n",
    "S_cured[0] = 0.0 \n",
    "\n",
    "# 3. Reconstruct the matrix\n",
    "# W = U * S * V^T\n",
    "W_cured = U @ torch.diag(S_cured) @ Vh\n",
    "\n",
    "# 4. Implant back into the model\n",
    "target_layer.weight.data = W_cured\n",
    "\n",
    "print(\"üè• Surgery Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the Cure\n",
    "print(f\"Cured Output: {generate_text(prompt)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "We successfully identified and removed a specific behavioral mode from the model using only linear algebra. \n",
    "\n",
    "This demonstrates the principle behind **DeepSeek R1 Slim**: By mapping the weight matrix to its Singular Values, we can identify \"artificial\" constraints (like censorship) and delete them while preserving the natural \"knowledge\" (which lives in the other singular values)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
